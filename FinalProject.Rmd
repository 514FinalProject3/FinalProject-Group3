---
title: "FinalProject"
author: "Group 3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tigerstats)
library(readr)
library(tidyverse)
#library(webr)
```

## Section 1 - Loading the data and Exploring the data

We have selected Bike dataset to perform exploration of the data. We start by loading the data into the R Markdown file

```{r}
bike_data <- read_csv("Cleaned_bike_data.csv",show_col_types = FALSE)
```


```{r}
summary(bike_data)
```

We can see that there are different columns in the table which are Model_name, Model_year, Kms_driven, Owner, Location, Mileage, Power and Price.

To determine the different types of the datatypes, we can use the str command in R. This command tells us the different types of data which is present in the datasheet.
```{r}
str(bike_data)
```

The different types of datatypes which are present in the dataset are numeric and charachter.  

To determine the null values in the table, we can use the built in method in R. 

```{r}
null_values <- sum(is.na(bike_data)) 
null_values
```

With the above method, we can see that there are 0 missing/Null values in the dataset.

## Part 2 - Graphical Overview

You can also embed plots, for example:

```{r pressure, echo=FALSE}
hist(bike_data$model_year, main = "Frequency of Bikes per Model Year", xlab = "Model Year", ylab = "Frequency")
boxplot(bike_data$power)
```

## Part 3 - Hypothesis Testing

```{r }
data <- read.csv("Cleaned_bike_data.csv")
str(data)
```

### Testing First hand owner price higher the Second hand owner (One-side test)

\begin{align*}
H_0: \mu_{first\_owner\_price}-\mu_{second\_owner\_price} & = 0 \\
H_1: \mu_{first\_owner\_price}-\mu_{second\_owner\_price} & > 0 
\end{align*}

```{r , fig.width=8, fig.height=7}


#split first hand owner and second hand owner
first_hand_owner <- subset(data, owner=="first owner")
second_hand_owner <- subset(data, owner=="second owner")


first_second_owner <- rbind(first_hand_owner, second_hand_owner)


ggplot(first_second_owner, aes(x=owner, y=price, fill=owner)) + 
    geom_boxplot(alpha=0.8) +
    theme(legend.position="none") +
    scale_fill_brewer(palette="Dark2") +
    coord_flip()
```
#### Don't know variance. So, use T-testing but need to check variance whether or not equal. \
#### Check variance equal or not \

\begin{align*}
H_0: \sigma_{first\_owner\_price}^2 = \sigma_{second\_owner\_price}^2 \\
H_1:  \sigma_{first\_owner\_price}^2 \ne \sigma_{second\_owner\_price}^2 
\end{align*}

```{r , fig.width=8, fig.height=7}
var.test(first_hand_owner$price, second_hand_owner$price, alternative = "two.sided")
#Not reject H0 => variance equal

#t-testing
t.test(first_hand_owner$price, second_hand_owner$price,alternative="greater", var.equal = TRUE, conf.level = 0.95)

plot(t.test(first_hand_owner$price, second_hand_owner$price,alternative="greater", var.equal = TRUE, conf.level = 0.95))

```
\
>Should not reject Mu(first_price)=Mu(second_price) 


### Testing Price of Second hand bike not be different from third and later (Two-side test) \

\begin{align*}
H_0: \mu_{second\_owner\_price}-\mu_{later\_second\_owner\_price} & = 0 \\
H_1: \mu_{second\_owner\_price}-\mu_{later\_second\_owner\_price} & > 0 
\end{align*}


```{r, fig.width=8, fig.height=7}
second_hand_owner <- subset(data, owner=="second owner")
later_second_hand_owner <- subset(data, owner =="third owner" | owner == "fourth owner or more")

later_second_hand_owner$owner[later_second_hand_owner$owner == "third owner" | later_second_hand_owner$owner == "fourth owner or more"]<- "third owner or more"

second_later_owner <- rbind(second_hand_owner, later_second_hand_owner)


ggplot(second_later_owner, aes(x=owner, y=price, fill=owner)) + 
    geom_boxplot(alpha=0.8) +
    theme(legend.position="none") +
    scale_fill_brewer(palette="Dark2") +
    coord_flip()
```


#### Don't know variance. So, use T-testing but need to check variance whether or not equal. \
#### Check variance equal or not \
\begin{align*}
H_0: \sigma_{second\_owner\_price}^2 = \sigma_{later\_second\_owner\_price}^2 \\
H_1:  \sigma_{second\_owner\_price}^2 \ne \sigma_{later\_second\_owner\_price}^2 
\end{align*}

```{r, fig.width=8, fig.height=7}
var.test(second_hand_owner$price, later_second_hand_owner$price, alternative = "two.sided")
#reject H0 => variance not equal

#t-testing
t.test(second_hand_owner$price, later_second_hand_owner$price,alternative="two.sided", var.equal = FALSE, conf.level = 0.95)

plot(t.test(second_hand_owner$price, later_second_hand_owner$price,alternative="two.sided", var.equal = FALSE, conf.level = 0.95))
```
\
> Should reject Mu(second_price)=Mu(later_second_price) => (Mu(second_price) != Mu(later_second_price)


### Testing Higher median kms driven price cheaper than lower median kms driven price (One side test)

\begin{align*}
H_0: \mu_{greater\_median\_kms\_driven}-\mu_{less\_median\_kms\_driven} & = 0 \\
H_1: \mu_{greater\_median\_kms\_driven}-\mu_{less\_median\_kms\_driven} & > 0
\end{align*}

```{r,  fig.width=8, fig.height=7}
median(data$kms_driven)


greater_median_kms_driven <- subset(data, kms_driven > 18000)
less_median_kms_driven <- subset(data, kms_driven <= 18000)

greater_median_kms_driven["median_kms_driven"] <- "greater"
less_median_kms_driven["median_kms_driven"] <- "less"

all_kms_driven <- rbind(greater_median_kms_driven, less_median_kms_driven)


ggplot(all_kms_driven, aes(x=median_kms_driven, y=price, fill=median_kms_driven)) + 
    geom_boxplot(alpha=0.8) +
    theme(legend.position="none") +
    scale_fill_brewer(palette="Dark2") +
    coord_flip()

```

#### Don't know variance. So, use T-testing but need to check variance whether or not equal.
#### Check variance equal or not
\begin{align*}
H_0: \sigma_{greater\_median\_kms\_driven\_price}^2 = \sigma_{less\_median\_kms\_driven\_price}^2 \\
H_1:  \sigma_{greater\_median\_kms\_driven\_price}^2 \ne \sigma_{less\_median\_kms\_driven\_price}^2 
\end{align*}

```{r, fig.width=8, fig.height=7}
var.test(greater_median_kms_driven$price, less_median_kms_driven$price , alternative = "two.sided")
# reject H0 => variance not equal

#t-testing
t.test(greater_median_kms_driven$price, less_median_kms_driven$price,alternative="less", var.equal = FALSE, conf.level = 0.95)

plot(t.test(greater_median_kms_driven$price, less_median_kms_driven$price,alternative="less", var.equal = FALSE, conf.level = 0.95))
```
\
> Should reject H0 Mu(over_mean_kms_driven_price)=Mu(less_mean_kms_driven_price) => Mu(over_mean_kms_driven_price)< Mu(less_mean_kms_driven_price)




## Part 4 - Linear Regression

This section is for Linear Regression.

Including the necessary packages for regression
```{r}
library(MASS)
library(MLmetrics)
```

Setting the seed to store the data and keep it same.

```{r}
set.seed(101)
```

Splitting the Dataset into Training and Testing Dataset randomly. We have splitted the data in 70% and 30%.

```{r}
i = sample(2, nrow(bike_data), replace=TRUE, prob=c(0.7, 0.3))
bikeTraining <- bike_data[i==1,]
bikeTesting <- bike_data[i==2,]
```
The Training Dataset consists of 3554 entries and the Testing dataset consists of 1508 entries. 

# Model 1 - Forward Propogation Model.

We start with constructing the intercept model. The intercept is used to form a linear regression model with a constant variable. The full model is used to select all the attributes which are seen in the data table. We then use the stepAIC function to travel step by step and select all the elements with the highest AIC until the occurrence of the null variable. 

```{r}
intercept_model <- lm(price ~ 1, data = bikeTraining[,1:8])
full_model <- lm(price ~ .-model_name, data = bikeTraining[,1:8])
forward_model <- stepAIC(intercept_model, direction = "forward",scope = formula(full_model))
```

As we can see that the full model is constructed without the use of the model name. The reason for not including the model name is that it is not revelant to the price. 


```{r}
summary(forward_model)
forward_model$anova
```

### We can calculate the MAE and MSE for both the backward model as follows:

```{r}
forward_pred <-predict(object = forward_model, newdata = bikeTesting[,1:8])
MAE(y_pred = forward_pred, y_true = bikeTesting$price)
MSE(y_pred = forward_pred, y_true = bikeTesting$price)
```

### Plotting the Forward Propogation Model

```{r}
par(mfrow=c(2,2))
plot(forward_model)
```

# Model 2 - Backward Propogation

```{r}
backward <- stepAIC(full_model, direction = "backward")
summary(backward)
```

> We see that the accuracy of the backward model is similar to that of the forward model. 

### Calculation of the MAE and MSE for the backward model 

```{r}
backward_pred <-predict(object = backward, newdata = bikeTesting[,1:8])
MAE(y_pred = backward_pred, y_true = bikeTesting$price)
MSE(y_pred = backward_pred, y_true = bikeTesting$price)
```

### Plotting the Backward Propogation model 

```{r}
par(mfrow = c(2,2))
plot(backward)
```


> We can see that both the models have the same accuracy and same mean square error and Mean absolute error. The accuracy for both the models is 77.02%.
